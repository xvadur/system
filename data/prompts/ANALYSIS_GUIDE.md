# üìñ Kompletn√Ω N√°vod na Anal√Ωzu Promptov

**√öƒçel:** N√°vod na extrakciu aktiv√≠t a NLP anal√Ωzu promptov  
**Skripty:** 
- `scripts/extract_prompt_activities.py` - Extrakcia aktiv√≠t
- `scripts/analyze_prompts_nlp4sk.py` - NLP anal√Ωza

---

## üìã Obsah

1. [Extrakcia Aktiv√≠t z Promptov](#extrakcia-aktivit)
2. [Lok√°lna NLP Anal√Ωza](#lok√°lna-nlp-anal√Ωza)
3. [Pr√≠klady Pou≈æitia](#pr√≠klady-pou≈æitia)

---

## üîç Extrakcia Aktiv√≠t

**Skript:** `scripts/extract_prompt_activities.py`  
**V√Ωstup:** `data/prompts/prompts_activities.jsonl`

### R√Ωchly ≈†tart

#### 1. Nastavenie API Key

**Odpor√∫ƒçan√©:** Vytvor `.env` s√∫bor v root adres√°ri workspace:

```bash
# Skop√≠ruj template
cp .env.example .env

# Uprav .env a nahraƒè 'sk-...' svoj√≠m skutoƒçn√Ωm API kƒæ√∫ƒçom
# Z√≠skaj ho z: https://platform.openai.com/api-keys
```

Alebo nastav environment variable (doƒçasn√©):
```bash
export OPENAI_API_KEY='sk-...'
```

**Pozn√°mka:** `.env` s√∫bor je u≈æ v `.gitignore`, tak≈æe sa necommitne do gitu.

#### 2. Test Mode (Odpor√∫ƒçan√© na zaƒçiatok)

V `scripts/extract_prompt_activities.py` nastav:
```python
TEST_MODE = True
TEST_LIMIT = 20
```

Spusti:
```bash
python3 scripts/extract_prompt_activities.py
```

Toto spracuje len prv√Ωch 20 promptov pre testovanie.

#### 3. Pln√© Spracovanie

V `scripts/extract_prompt_activities.py` nastav:
```python
TEST_MODE = False
```

Spusti:
```bash
python3 scripts/extract_prompt_activities.py
```

### ƒåo Skript Rob√≠

1. **Naƒç√≠ta prompty:**
   - Historick√©: `data/prompts/prompts_split/` (664 promptov)
   - Aktu√°lne: `xvadur/data/prompts_log.jsonl` (44 promptov)

2. **Filtruje:**
   - Preskoƒç√≠ prompty >= 1000 slov (dlh√© prompty)
   - Zost√°va ~606 promptov < 1000 slov

3. **Extrahuje:**
   - Pre ka≈æd√Ω prompt zavol√° OpenAI API
   - Extrahuje: aktivitu (ƒço robil) + my≈°lienky (nad ƒç√≠m rozm√Ω≈°ƒæal)

4. **Uklad√°:**
   - Do `data/prompts/prompts_activities.jsonl`
   - Resume functionality - ak skript spadne, m√¥≈æe pokraƒçova≈•

### Form√°t V√Ωstupu

**S√∫bor:** `data/prompts/prompts_activities.jsonl`

```json
{
  "prompt_id": "2025-09-15_001",
  "date": "2025-09-15",
  "timestamp": "2025-09-15T13:18:41.861000+00:00",
  "word_count": 738,
  "activity": "P√≠sal filozofick√∫ √∫vahu o hist√≥rii ƒæudstva, kres≈•anstve a Jungovi",
  "thoughts": "Rozm√Ω≈°ƒæal o princ√≠poch civiliz√°ci√≠, manipul√°cii mas, kres≈•anstve a jeho interpret√°cii, Jungovej dekon≈°trukcii boha",
  "summary_extracted_at": "2025-12-03T16:00:00+01:00"
}
```

### Konfigur√°cia

V `scripts/extract_prompt_activities.py`:

```python
MAX_WORDS = 1000          # Limit pre spracovanie
BATCH_SIZE = 10           # Progress update ka≈æd√Ωch N promptov
MODEL = "gpt-4o-mini"     # OpenAI model (gpt-4o-mini alebo gpt-4o)
TEST_MODE = False         # Test mode (len prv√Ωch N promptov)
TEST_LIMIT = 20           # Poƒçet promptov v test mode
```

### Resume Functionality

Ak skript spadne alebo ho preru≈°√≠≈°:
- Skript automaticky naƒç√≠ta u≈æ spracovan√© prompty z output s√∫boru
- Preskoƒç√≠ ich a pokraƒçuje len s nov√Ωmi
- M√¥≈æe≈° ho spusti≈• znova bez ob√°v o duplik√°ty

### Odhadovan√© N√°klady

- **Poƒçet promptov:** ~606 promptov < 1000 slov
- **Model:** gpt-4o-mini (~$0.15 per 1M input tokens, ~$0.60 per 1M output tokens)
- **Odhadovan√© n√°klady:** $2-5 pre v≈°etky prompty
- **ƒåas:** ~10-15 min√∫t (s rate limiting 1.1s medzi requestmi)

### Troubleshooting (Extrakcia)

**Chyba: "OPENAI_API_KEY nie je nastaven√Ω"**
```bash
export OPENAI_API_KEY='sk-...'
```

**Chyba: "Rate limit exceeded"**
- Skript automaticky ƒçak√° medzi requestmi (1.1s)
- Ak st√°le zlyh√°, zv√Ω≈° ƒças medzi requestmi v k√≥de

**Chyba: "JSON decode error"**
- Skript m√° fallback parsing pre textov√© odpovede
- Chyby sa loguj√∫ do `data/prompts/extraction_errors.log`

---

## üß† Lok√°lna NLP Anal√Ωza

**Skript:** `scripts/analyze_prompts_nlp4sk.py`  
**V√Ωstup:** `data/prompts/prompts_nlp4sk.jsonl`  
**N√°stroje:** Stanza, Hugging Face Transformers

### R√Ωchly ≈†tart

#### 1. In≈°tal√°cia Z√°vislost√≠

Nain≈°taluj potrebn√© Python bal√≠ky:

```bash
pip install stanza transformers torch
```

**Pozn√°mka:** PyTorch m√¥≈æe by≈• veƒæk√Ω (~2GB). Ak m√°≈° GPU, nain≈°taluj `torch` s CUDA podporou.

#### 2. Stiahnutie Stanza Modelu

Prv√© spustenie skriptu automaticky stiahne slovensk√Ω model (~500MB), ale m√¥≈æe≈° ho stiahnu≈• manu√°lne:

```bash
python3 -c "import stanza; stanza.download('sk')"
```

**ƒåas:** ~2-5 min√∫t (z√°vis√≠ od r√Ωchlosti internetu)

#### 3. Test Mode (Odpor√∫ƒçan√© na zaƒçiatok)

V `scripts/analyze_prompts_nlp4sk.py` nastav:
```python
TEST_MODE = True
TEST_LIMIT = 20
```

Spusti:
```bash
python3 scripts/analyze_prompts_nlp4sk.py
```

Toto spracuje len prv√Ωch 20 promptov pre testovanie.

#### 4. Pln√© Spracovanie

V `scripts/analyze_prompts_nlp4sk.py` nastav:
```python
TEST_MODE = False
```

Spusti:
```bash
python3 scripts/analyze_prompts_nlp4sk.py
```

### ƒåo Skript Rob√≠

1. **Naƒç√≠ta prompty:**
   - Z `data/prompts/prompts_activities.jsonl` (650 aktiv√≠t)

2. **Analyzuje pomocou lok√°lnych NLP n√°strojov:**
   - **Sentiment anal√Ωza:** Hugging Face transformers (multilingual model)
   - **Extrakcia ent√≠t (NER):** Stanza NER (people, organizations, locations, technologies)
   - **Extrakcia pojmov:** Stanza (noun phrases a v√Ωznamn√© slov√°)

3. **Uklad√°:**
   - Do `data/prompts/prompts_nlp4sk.jsonl`
   - Resume functionality - ak skript spadne, m√¥≈æe pokraƒçova≈•

### Form√°t V√Ωstupu

**S√∫bor:** `data/prompts/prompts_nlp4sk.jsonl`

```json
{
  "prompt_id": "2025-09-15_001",
  "date": "2025-09-15",
  "timestamp": "2025-09-15T13:18:41.861000+00:00",
  "word_count": 738,
  "sentiment": "positive",
  "sentiment_score": 0.85,
  "people": ["Vlado", "Petr"],
  "organizations": ["OpenAI"],
  "locations": [],
  "technologies": ["n8n", "Chainlit", "MCP"],
  "concepts": ["projekt", "automatiz√°cia", "workflow"],
  "analyzed_at": "2025-12-03T16:00:00+01:00"
}
```

### Pou≈æit√© N√°stroje

#### Stanza

- **√öƒçel:** NER (Named Entity Recognition), tokeniz√°cia, lematiz√°cia, POS tagging
- **Model:** Slovensk√Ω model (`sk`)
- **Veƒækos≈•:** ~500MB
- **Prv√© spustenie:** Automaticky stiahne model

**Funkcie:**
- Extrakcia ent√≠t (people, organizations, locations)
- Identifik√°cia technol√≥gi√≠ (podƒæa kƒæ√∫ƒçov√Ωch slov)
- Extrakcia pojmov (podstatn√© men√° a vlastn√© men√°)

#### Hugging Face Transformers

- **√öƒçel:** Sentiment anal√Ωza
- **Model:** `cardiffnlp/twitter-xlm-roberta-base-sentiment` (multilingual)
- **Veƒækos≈•:** ~500MB
- **Prv√© spustenie:** Automaticky stiahne model

**Funkcie:**
- Anal√Ωza sentimentu (positive, negative, neutral)
- Sentiment score (0.0-1.0)

### Konfigur√°cia

V `scripts/analyze_prompts_nlp4sk.py`:

```python
BATCH_SIZE = 10           # Progress update ka≈æd√Ωch N promptov
TEST_MODE = False         # Test mode (len prv√Ωch N promptov)
TEST_LIMIT = 20           # Poƒçet promptov v test mode
```

### Resume Functionality

Ak skript spadne alebo ho preru≈°√≠≈°:
- Skript automaticky naƒç√≠ta u≈æ spracovan√© prompty z output s√∫boru
- Preskoƒç√≠ ich a pokraƒçuje len s nov√Ωmi
- M√¥≈æe≈° ho spusti≈• znova bez ob√°v o duplik√°ty

### N√°klady a Performance

#### N√°klady
- **Zdarma:** ≈Ωiadne API n√°klady
- **Disk:** ~1-2 GB (modely)
- **RAM:** ~2-4 GB poƒças spracovania

#### Performance
- **Prv√© spustenie:** ~5-10 min√∫t (stiahnutie modelov)
- **ƒåas spracovania:** ~15-20 min√∫t pre 650 promptov (CPU)
- **S GPU:** ~5-10 min√∫t pre 650 promptov

### Troubleshooting (NLP Anal√Ωza)

**Chyba: "ModuleNotFoundError: No module named 'stanza'"**
```bash
pip install stanza transformers torch
```

**Chyba: "Chyba pri inicializ√°cii Stanza"**
```bash
# Stiahni slovensk√Ω model manu√°lne
python3 -c "import stanza; stanza.download('sk')"
```

**Chyba: "Out of memory"**
- Transformers modely m√¥≈æu by≈• pam√§≈•ovo n√°roƒçn√©
- Sk√∫s spracova≈• menej promptov naraz (TEST_MODE)
- Alebo pou≈æij GPU (ak m√°≈°)

**Chyba: "Model not found"**
- Prv√© spustenie automaticky stiahne modely
- Ak zlyh√°, stiahni manu√°lne:
  ```bash
  python3 -c "import stanza; stanza.download('sk')"
  ```

**Pomal√© spracovanie**
- Norm√°lne pre CPU (15-20 min pre 650 promptov)
- Ak m√°≈° GPU, m√¥≈æe≈° upravi≈• `device=-1` na `device=0` v `init_sentiment_pipeline()`

---

## üìù Pr√≠klady Pou≈æitia

### Extrakcia Aktiv√≠t

#### Naƒç√≠ta≈• aktivity pre mesiac:
```python
import json
from pathlib import Path

activities = []
with open('data/prompts/prompts_activities.jsonl', 'r') as f:
    for line in f:
        data = json.loads(line)
        if data['date'].startswith('2025-09'):
            activities.append(data)

for act in activities:
    print(f"{act['date']}: {act['activity']}")
```

#### Vyhƒæada≈• podƒæa aktivity:
```python
# N√°js≈• v≈°etky prompty o AI
ai_activities = [a for a in activities if 'ai' in a['activity'].lower()]
```

### NLP Anal√Ωza

#### Naƒç√≠ta≈• anal√Ωzy pre mesiac:
```python
import json
from pathlib import Path

analyses = []
with open('data/prompts/prompts_nlp4sk.jsonl', 'r') as f:
    for line in f:
        data = json.loads(line)
        if data['date'].startswith('2025-09'):
            analyses.append(data)

for analysis in analyses:
    print(f"{analysis['date']}: sentiment={analysis.get('sentiment')}, people={analysis.get('people')}")
```

#### Vyhƒæada≈• podƒæa sentimentu:
```python
# N√°js≈• v≈°etky negat√≠vne prompty
negative = [a for a in analyses if a.get('sentiment') == 'negative']
```

#### Vyhƒæada≈• podƒæa technol√≥gi√≠:
```python
# N√°js≈• v≈°etky prompty o n8n
n8n_prompts = [a for a in analyses if 'n8n' in a.get('technologies', [])]
```

#### Vyhƒæada≈• podƒæa ƒæud√≠:
```python
# N√°js≈• v≈°etky prompty o Vlado
vlado_prompts = [a for a in analyses if 'Vlado' in a.get('people', [])]
```

### Kombinovan√° Anal√Ωza

#### Spoji≈• aktivity s NLP anal√Ωzou:
```python
import json

# Naƒç√≠ta≈• aktivity
activities = {}
with open('data/prompts/prompts_activities.jsonl', 'r') as f:
    for line in f:
        data = json.loads(line)
        activities[data['prompt_id']] = data

# Naƒç√≠ta≈• NLP anal√Ωzy
analyses = {}
with open('data/prompts/prompts_nlp4sk.jsonl', 'r') as f:
    for line in f:
        data = json.loads(line)
        analyses[data['prompt_id']] = data

# Spoji≈• d√°ta
for prompt_id in activities:
    if prompt_id in analyses:
        activity = activities[prompt_id]
        analysis = analyses[prompt_id]
        print(f"{activity['date']}: {activity['activity']} | Sentiment: {analysis.get('sentiment')}")
```

---

## üîó Workflow

**Odpor√∫ƒçan√Ω postup:**

1. **Krok 1:** Extrahuj aktivity z promptov
   ```bash
   python3 scripts/extract_prompt_activities.py
   ```
   V√Ωstup: `data/prompts/prompts_activities.jsonl`

2. **Krok 2:** Spusti NLP anal√Ωzu na extrahovan√Ωch aktivit√°ch
   ```bash
   python3 scripts/analyze_prompts_nlp4sk.py
   ```
   V√Ωstup: `data/prompts/prompts_nlp4sk.jsonl`

3. **Krok 3:** Pou≈æi d√°ta pre anal√Ωzy, vizualiz√°cie, alebo ƒèal≈°ie spracovanie

---

## üìö ƒéal≈°ie Zdroje

- **Stanza:** https://stanfordnlp.github.io/stanza/
- **Hugging Face:** https://huggingface.co/
- **Transformers:** https://huggingface.co/docs/transformers/
- **OpenAI API:** https://platform.openai.com/api-keys

---

**Vytvoren√©:** 2025-12-03  
**Status:** ‚úÖ Pripraven√© na pou≈æitie

