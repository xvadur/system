#!/usr/bin/env python3
"""
PripraviÅ¥ OpenAI Fine-tuning Dataset

Tento skript:
1. NaÄÃ­ta conversation_pairs_guaranteed.jsonl
2. Konvertuje do OpenAI fine-tuning formÃ¡tu (messages array)
3. Validuje dataset podÄ¾a OpenAI poÅ¾iadaviek
4. UloÅ¾Ã­ do JSONL sÃºboru pripravenÃ©ho na upload
5. VytvorÃ­ Å¡tatistiky datasetu
"""

import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict

# PridÃ¡me workspace root do sys.path
workspace_root = Path(__file__).parent.parent
sys.path.insert(0, str(workspace_root))

# KonfigurÃ¡cia
INPUT_FILE = Path("xvadur/data/kortex_guaranteed/conversation_pairs_guaranteed.jsonl")
OUTPUT_DIR = Path("xvadur/data/finetuning")
OUTPUT_FILE = OUTPUT_DIR / "openai_finetuning_dataset.jsonl"
STATS_FILE = OUTPUT_DIR / "finetuning_stats.json"

# OpenAI poÅ¾iadavky
MIN_EXAMPLES = 10
MAX_TOKENS_ESTIMATE = 1000000  # Odhad (1 token â‰ˆ 4 znaky)


def estimate_tokens(text: str) -> int:
    """
    Odhad poÄtu tokenov (1 token â‰ˆ 4 znaky pre angliÄtinu/slovenÄinu).
    Pre presnejÅ¡Ã­ odhad by sa pouÅ¾il tiktoken, ale to nie je nutnÃ©.
    """
    return len(text) // 4


def validate_example(messages: List[Dict[str, str]]) -> tuple[bool, Optional[str]]:
    """
    Validuje jeden prÃ­klad podÄ¾a OpenAI poÅ¾iadaviek.
    
    Returns:
        (is_valid, error_message)
    """
    # Kontrola formÃ¡tu
    if not isinstance(messages, list):
        return False, "Messages musÃ­ byÅ¥ list"
    
    if len(messages) < 2:
        return False, "Messages musÃ­ obsahovaÅ¥ aspoÅˆ user a assistant"
    
    # Kontrola role
    roles = [msg.get("role") for msg in messages]
    if "user" not in roles or "assistant" not in roles:
        return False, "Messages musÃ­ obsahovaÅ¥ role 'user' a 'assistant'"
    
    # Kontrola content
    for msg in messages:
        if not isinstance(msg, dict):
            return False, "KaÅ¾dÃ¡ message musÃ­ byÅ¥ dict"
        if "role" not in msg or "content" not in msg:
            return False, "KaÅ¾dÃ¡ message musÃ­ maÅ¥ 'role' a 'content'"
        if not isinstance(msg["content"], str):
            return False, "Content musÃ­ byÅ¥ string"
        if not msg["content"].strip():
            return False, "Content nemÃ´Å¾e byÅ¥ prÃ¡zdny"
    
    return True, None


def convert_pair_to_openai_format(pair: Dict[str, Any]) -> Optional[Dict[str, List[Dict[str, str]]]]:
    """
    Konvertuje conversation pair do OpenAI fine-tuning formÃ¡tu.
    
    FormÃ¡t:
    {
        "messages": [
            {"role": "user", "content": "..."},
            {"role": "assistant", "content": "..."}
        ]
    }
    """
    try:
        user_text = pair.get("user_prompt", {}).get("extracted_text", "")
        ai_text = pair.get("ai_response", {}).get("extracted_text", "")
        
        # Kontrola prÃ¡zdnych textov
        if not user_text or not user_text.strip():
            return None
        if not ai_text or not ai_text.strip():
            return None
        
        # Vytvorenie messages array
        messages = [
            {"role": "user", "content": user_text.strip()},
            {"role": "assistant", "content": ai_text.strip()}
        ]
        
        # ValidÃ¡cia
        is_valid, error = validate_example(messages)
        if not is_valid:
            print(f"âš ï¸  NeplatnÃ½ prÃ­klad: {error}")
            return None
        
        return {"messages": messages}
    
    except Exception as e:
        print(f"âš ï¸  Chyba pri konverzii pÃ¡ru: {e}")
        return None


def load_conversation_pairs(input_file: Path) -> List[Dict[str, Any]]:
    """NaÄÃ­ta conversation pairs z JSONL sÃºboru."""
    pairs = []
    
    if not input_file.exists():
        print(f"âŒ SÃºbor neexistuje: {input_file}")
        sys.exit(1)
    
    print(f"ğŸ“– NaÄÃ­tavam conversation pairs z: {input_file}")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                pair = json.loads(line)
                pairs.append(pair)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  Chyba pri parsovanÃ­ riadku {line_num}: {e}")
                continue
    
    print(f"âœ… NaÄÃ­tanÃ½ch {len(pairs)} conversation pairs")
    return pairs


def prepare_dataset(pairs: List[Dict[str, Any]]) -> tuple[List[Dict], Dict[str, Any]]:
    """
    Konvertuje pairs do OpenAI formÃ¡tu a vytvorÃ­ Å¡tatistiky.
    
    Returns:
        (valid_examples, stats)
    """
    valid_examples = []
    invalid_count = 0
    
    # Å tatistiky
    total_user_length = 0
    total_assistant_length = 0
    total_tokens = 0
    
    print(f"\nğŸ”„ Konvertujem {len(pairs)} pÃ¡rov do OpenAI formÃ¡tu...")
    
    for i, pair in enumerate(pairs, 1):
        if i % 100 == 0:
            print(f"   SpracovanÃ½ch {i}/{len(pairs)}...")
        
        openai_format = convert_pair_to_openai_format(pair)
        
        if openai_format:
            valid_examples.append(openai_format)
            
            # Å tatistiky
            user_content = openai_format["messages"][0]["content"]
            assistant_content = openai_format["messages"][1]["content"]
            
            total_user_length += len(user_content)
            total_assistant_length += len(assistant_content)
            total_tokens += estimate_tokens(user_content) + estimate_tokens(assistant_content)
        else:
            invalid_count += 1
    
    # Vytvorenie Å¡tatistÃ­k
    stats = {
        "total_examples": len(pairs),
        "valid_examples": len(valid_examples),
        "invalid_examples": invalid_count,
        "avg_user_length": total_user_length // len(valid_examples) if valid_examples else 0,
        "avg_assistant_length": total_assistant_length // len(valid_examples) if valid_examples else 0,
        "total_tokens_estimate": total_tokens,
        "file_size_mb": 0.0  # VypoÄÃ­tame neskÃ´r
    }
    
    return valid_examples, stats


def save_dataset(examples: List[Dict], output_file: Path) -> int:
    """UloÅ¾Ã­ dataset do JSONL sÃºboru a vrÃ¡ti veÄ¾kosÅ¥ sÃºboru v bytoch."""
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ’¾ UkladÃ¡m dataset do: {output_file}")
    
    total_bytes = 0
    with open(output_file, 'w', encoding='utf-8') as f:
        for example in examples:
            line = json.dumps(example, ensure_ascii=False)
            f.write(line + '\n')
            total_bytes += len(line.encode('utf-8')) + 1  # +1 pre newline
    
    file_size_mb = total_bytes / (1024 * 1024)
    print(f"âœ… Dataset uloÅ¾enÃ½ ({len(examples)} prÃ­kladov, {file_size_mb:.2f} MB)")
    
    return total_bytes


def validate_dataset(examples: List[Dict]) -> tuple[bool, List[str]]:
    """
    Validuje celÃ½ dataset podÄ¾a OpenAI poÅ¾iadaviek.
    
    Returns:
        (is_valid, errors)
    """
    errors = []
    
    # MinimÃ¡lny poÄet prÃ­kladov
    if len(examples) < MIN_EXAMPLES:
        errors.append(f"Dataset musÃ­ obsahovaÅ¥ aspoÅˆ {MIN_EXAMPLES} prÃ­kladov (mÃ¡ {len(examples)})")
    
    # ValidÃ¡cia kaÅ¾dÃ©ho prÃ­kladu
    for i, example in enumerate(examples, 1):
        is_valid, error = validate_example(example.get("messages", []))
        if not is_valid:
            errors.append(f"PrÃ­klad {i}: {error}")
    
    return len(errors) == 0, errors


def main():
    """HlavnÃ¡ funkcia."""
    print("=" * 60)
    print("ğŸš€ PripraviÅ¥ OpenAI Fine-tuning Dataset")
    print("=" * 60)
    
    # 1. NaÄÃ­tanie conversation pairs
    pairs = load_conversation_pairs(INPUT_FILE)
    
    if not pairs:
        print("âŒ Å½iadne conversation pairs na spracovanie")
        sys.exit(1)
    
    # 2. Konverzia do OpenAI formÃ¡tu
    valid_examples, stats = prepare_dataset(pairs)
    
    if not valid_examples:
        print("âŒ Å½iadne platnÃ© prÃ­klady po konverzii")
        sys.exit(1)
    
    # 3. ValidÃ¡cia datasetu
    print(f"\nâœ… Validujem dataset...")
    is_valid, errors = validate_dataset(valid_examples)
    
    if not is_valid:
        print("âŒ ValidÃ¡cia zlyhala:")
        for error in errors[:10]:  # ZobrazÃ­me prvÃ½ch 10 chÃ½b
            print(f"   - {error}")
        if len(errors) > 10:
            print(f"   ... a ÄalÅ¡Ã­ch {len(errors) - 10} chÃ½b")
        sys.exit(1)
    
    print("âœ… ValidÃ¡cia ÃºspeÅ¡nÃ¡")
    
    # 4. UloÅ¾enie datasetu
    total_bytes = save_dataset(valid_examples, OUTPUT_FILE)
    stats["file_size_mb"] = total_bytes / (1024 * 1024)
    
    # 5. UloÅ¾enie Å¡tatistÃ­k
    print(f"\nğŸ’¾ UkladÃ¡m Å¡tatistiky do: {STATS_FILE}")
    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    print("âœ… Å tatistiky uloÅ¾enÃ©")
    
    # 6. Zhrnutie
    print("\n" + "=" * 60)
    print("âœ… HOTOVO!")
    print("=" * 60)
    print(f"ğŸ“Š Å tatistiky:")
    print(f"   - CelkovÃ½ poÄet prÃ­kladov: {stats['total_examples']}")
    print(f"   - PlatnÃ½ch prÃ­kladov: {stats['valid_examples']}")
    print(f"   - NeplatnÃ½ch prÃ­kladov: {stats['invalid_examples']}")
    print(f"   - PriemernÃ¡ dÄºÅ¾ka user promptu: {stats['avg_user_length']} znakov")
    print(f"   - PriemernÃ¡ dÄºÅ¾ka AI odpovede: {stats['avg_assistant_length']} znakov")
    print(f"   - OdhadovanÃ½ poÄet tokenov: {stats['total_tokens_estimate']:,}")
    print(f"   - VeÄ¾kosÅ¥ sÃºboru: {stats['file_size_mb']:.2f} MB")
    print(f"\nğŸ“ Dataset pripravenÃ½ na upload:")
    print(f"   {OUTPUT_FILE}")
    print(f"\nğŸ’¡ ÄalÅ¡ie kroky:")
    print(f"   1. Otvor https://platform.openai.com/finetuning")
    print(f"   2. Upload sÃºbor: {OUTPUT_FILE}")
    print(f"   3. Vyber model (gpt-3.5-turbo alebo gpt-4)")
    print(f"   4. Spusti trÃ©ning")


if __name__ == "__main__":
    main()


