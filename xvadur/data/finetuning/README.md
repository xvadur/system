# OpenAI Fine-tuning Dataset - Status

**DÃ¡tum vytvorenia:** 2025-12-04  
**Status:** âœ… Dataset pripravenÃ½, â¸ï¸ PozastavenÃ© (budget)

---

## âœ… ÄŒo je HotovÃ©

### 1. Dataset PripravenÃ½
- **SÃºbor:** `openai_finetuning_dataset.jsonl`
- **VeÄ¾kosÅ¥:** 15.42 MB
- **PrÃ­klady:** 1,822 konverzaÄnÃ½ch pÃ¡rov
- **FormÃ¡t:** OpenAI fine-tuning formÃ¡t (messages array)
- **ValidÃ¡cia:** âœ… VÅ¡etky prÃ­klady sÃº platnÃ©

### 2. Å tatistiky
- **CelkovÃ½ poÄet prÃ­kladov:** 1,822
- **PlatnÃ½ch prÃ­kladov:** 1,822 (100%)
- **NeplatnÃ½ch prÃ­kladov:** 0
- **PriemernÃ¡ dÄºÅ¾ka user promptu:** 3,626 znakov
- **PriemernÃ¡ dÄºÅ¾ka AI odpovede:** 4,572 znakov
- **OdhadovanÃ½ poÄet tokenov:** ~3.7M tokenov

### 3. Skript
- **SÃºbor:** `scripts/prepare_openai_finetuning.py`
- **Funkcionalita:** Konverzia conversation pairs â†’ OpenAI formÃ¡t
- **ValidÃ¡cia:** AutomatickÃ¡ validÃ¡cia podÄ¾a OpenAI poÅ¾iadaviek

---

## â¸ï¸ PozastavenÃ©

**DÃ´vod:** Budget obmedzenia (AutoTrain je platenÃ½, OpenAI mÃ¡ kvÃ³tu)

**ÄŒo zostÃ¡va:**
- Upload datasetu do finetuning platformy
- Spustenie trÃ©ningu
- Testovanie finetuned modelu

---

## ğŸ“‹ MoÅ¾nosti NeskÃ´r (KeÄ Bude Budget)

### 1. OpenAI Fine-tuning
- **NÃ¡klady:** ~$10-50 (trÃ©ning) + ~$0.03/1K tokenov (inference)
- **VÃ½hody:** NajjednoduchÅ¡ie, Playground UI
- **NevÃ½hody:** DrahÅ¡ie, kvÃ³ty

### 2. Hugging Face AutoTrain
- **NÃ¡klady:** ~$0.50-2/hodinu trÃ©ningu
- **VÃ½hody:** LacnejÅ¡ie, open-source modely
- **NevÃ½hody:** StÃ¡le platenÃ©

### 3. Together AI
- **NÃ¡klady:** ~$0.30-0.50/hodinu trÃ©ningu
- **VÃ½hody:** LacnejÅ¡ie ako OpenAI, podobnÃ© API
- **NevÃ½hody:** StÃ¡le platenÃ©

### 4. LokÃ¡lne RieÅ¡enie (Ollama + LoRA)
- **NÃ¡klady:** Zadarmo (ak mÃ¡Å¡ GPU)
- **VÃ½hody:** PlnÃ¡ kontrola, Å¾iadne limity
- **NevÃ½hody:** PotrebujeÅ¡ GPU, zloÅ¾itejÅ¡ie setup

---

## ğŸš€ ÄalÅ¡ie Kroky (KeÄ Bude Budget)

1. **VybraÅ¥ platformu** (OpenAI, Hugging Face, Together AI, alebo lokÃ¡lne)
2. **Upload datasetu** (`openai_finetuning_dataset.jsonl`)
3. **SpustiÅ¥ trÃ©ning** (1-3 hodiny)
4. **TestovaÅ¥ finetuned model**
5. **IntegrovaÅ¥ do produkcie** (AI recepÄnÃ¡, osobnÃ© AI)

---

## ğŸ“ SÃºbory

- `openai_finetuning_dataset.jsonl` - PripravenÃ½ dataset (15.42 MB, 1,822 prÃ­kladov)
- `finetuning_stats.json` - Å tatistiky datasetu
- `scripts/prepare_openai_finetuning.py` - Skript na konverziu

---

## ğŸ’¡ AlternatÃ­vy (ZatiaÄ¾ Bez Finetuningu)

Namiesto finetuningu mÃ´Å¾eÅ¡ pouÅ¾iÅ¥:

1. **RAG systÃ©m** - UÅ¾ mÃ¡Å¡ funkÄnÃ½ RAG systÃ©m, ktorÃ½ mÃ´Å¾e poskytovaÅ¥ kontext
2. **System prompts** - VylepÅ¡iÅ¥ system prompts s tvojÃ­m kontextom
3. **Few-shot learning** - PridaÅ¥ prÃ­klady do promptov
4. **RozÅ¡Ã­renie RAG** - PridaÅ¥ AI odpovede do RAG indexu (uÅ¾ plÃ¡novanÃ©)

---

**VytvorenÃ©:** 2025-12-04  
**Status:** â¸ï¸ PozastavenÃ© (budget)  
**PripravenÃ© na:** Finetuning neskÃ´r, keÄ bude budget


